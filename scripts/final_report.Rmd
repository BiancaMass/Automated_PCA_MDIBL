---
title: "Automated report"
output:
  html_document:
    toc: true
    toc_depth: 4
params:
  json: ""
  set_subtitle: "subtitle"
subtitle: "`r params$set_subtitle`"
date: "`r format(Sys.time())`"
---

```{r include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r include=FALSE}
library(jsonlite)
library(ggplot2)
library(grid)
library(gridExtra)
library(genefilter)
library(knitr)
library(stringr)
```

```{r}
# Read the json file:
path2_json_file = file.path(params$json)
json = read_json(path2_json_file)
parent_folder = file.path(json$folders$parent_folder)
experiment = json$input_files$experiment_name
json_copy = read_json(file.path(parent_folder, "results", paste0(experiment, "_json_copy.json")))
```

In this report you will find:

- Information about the input files and parameters.

- A summary of what each step in the pipeline does.

- Summary plots.

- Output tables.

## Input files
The input files can be found at the following location on your machine:
```{r}
path_2_design_file = json$input_files$infile1
path_2_counts_file = json$input_files$infile2
print(paste("Design file: ", path_2_design_file))
print(paste("Estimated counts file: ", path_2_counts_file))
```

```{r}
design = read.table(file.path(path_2_design_file), header = TRUE, sep = "\t", row.names = 1)
counts = read.table(file.path(path_2_counts_file), header = TRUE, sep = "\t", row.names = 1)
kable(design, caption = "Input design matrix.")
```

```{r}
kable(head(counts), caption = "The first 6 rows of the input estimated counts matrix")
```

```{r}
kable(summary(counts), caption ="Statistical summary of the estimated counts matrix.")
```

The input parameters are:
```{r}
print(json$input_variables)
```

## Scripts

### Step 0
step_00.R verifies that all required libraries are installed. If not, it will install them.

### Step 1

step_01.R makes sure that the input files are valid and compatible with the pipeline requirements. It performs the following operations:

- Checks that design and counts files exist.

- Checks that design and counts files are not empty.

- Prints a warning message if the est. count matrix has NAs.

- Checks for a 1-1 correspondence between the row names of the design file and the column names of the est. counts file.

### Step 2

step_02.R normalizes the matrix using rlog() or vst() depending whether sample number is, respectively, <= 30 or >30.
It performs the following operations:

- Checks there are no negative numbers in the count matrix.

- Rounds the count matrix to integers.

- Removes rows with few counts according to the variable set in the json->input_variables->min_gene_tot_raw_count.

- Filters for rows with a mean above the mean threshold set in the json->input_variables->min_count_mean.

- Calculates mean and standard deviation for each gene across all samples.

- Constructs a DESeq data set using the counts matrix, the design matrix, and as a design formula the one indicated in json->design_formula->design.

- Uses rlog() or vst() to normalized the count matrix, preparing it for PCA.

The means and standard deviations of each gene across samples (before any normalization) can be found at:

```{r}
path_2_counts_mean = json_copy$path_2_results$genecounts_means
path_2_counts_sd   = json_copy$path_2_results$genecounts_sd
print(paste("gene counts means: ", path_2_counts_mean))
print(paste("gene counts standard deviations: ", path_2_counts_sd))
```

The rlog() or vst() normalized matrix can be found at:

```{r}
if (file.exists(as.character(json_copy$path_2_results$normalized_rld))){
  path2_matrix_norm_1 = json_copy$path_2_results$normalized_rld
  print(path2_matrix_norm_1)
  norm_1 = read.table(path2_matrix_norm_1, header = TRUE, sep = "\t", row.names = 1)
  kable(head(norm_1), caption = "The first six rows of the matrix after rld() normalization.")
  kable(summary(norm_1), caption = "Statistical summary of the rld() normalized matrix.")
} else if (file.exists(as.character(json_copy$path_2_results$normalized_vst))) {
  path2_matrix_norm_1 = json_copy$path_2_results$normalized_vst
  norm_1 = read.table(path2_matrix_norm_1, header = TRUE, sep = "\t", row.names = 1)
  kable(head(norm_1), caption = "The first six rows of the matrix after vsd() normalization.")
  kable(summary(norm_1), caption = "Statistical summary of the vsd() normalized matrix.")
} else {print("There must have been an error in the running of the pipeline.
              Please check that all your input files match the requirements.
              If they do, refer to step_02.R for debugging.
              Feel free to contact the author if you have any questions.")}



```


### Step 3
step_03.R normalizes the output matrix from step 2 applying a Z-transformation such that $Z = (x-mean) / sd$ where mean and sd are the average and standard deviations of expression for that gene across all samples.
It performs the following operations:

- Calculates mean and standard deviation for each gene across all samples.

- Applies the Z-transform.

The Z table (after normalization) can be found at:
```{r}
path2_Z = json_copy$path_2_results$Z_table
print(path2_Z)
```

A Z table with two column added, one for mean and one for standard deviation of each gene across samples (before Z transform), can be found at:
```{r}
path2_Z_mn_sd = unlist(json_copy$path_2_results$Z_with_mean_sd)
print(path2_Z_mn_sd)
```

```{r}
figure1 = json_copy$figures$raw_mean_sd
figure2 = json_copy$figures$rld_mean_sd
figure3 = json_copy$figures$Z_mean_sd
```
Follow a series of figures of mean vs standard deviation of each gene across all samples for the raw counts (after filtering), after normalization with rlog() or vst(), and after the Z-transform.

```{r echo=FALSE, out.width = '50%', fig.cap="Fig 1. Mean vs standard deviation of the estimated count matrix after rows with a mean above the minimum threshold were filtered out (step 1 and 2)"}
knitr::include_graphics(figure1)
```

```{r echo=FALSE, out.width = '50%', fig.cap="Fig 2. Mean vs standard deviation after rlog() or vst() transformation"}
knitr::include_graphics(figure2)
```

```{r echo=FALSE, out.width = '50%', fig.cap="Fig 3. Mean vs standard deviation after Z transformation. If the pipeline worked properly, mean should be very close to 0 and standard deviations should be == 1."}
knitr::include_graphics(figure3)
```

### Step 4

step_04.R reduces to genes with either sufficient variation or average expression level. To do so, it uses the threshold on A and/or SD set in the JSON input file. It performs the following operations:

- Extracts the mean and sd threshold from the JSON file. Note: if they do not exist, or if they are not valid, default is set at first quartile (0.25)
  
- Subsets the Z normalized matrix by only keeping values above the threshold set in json->"input_variables"->"mean_precentage_threshold and json->"input_variables"->"sd_precentage_threshold"

Below is a visualization of the threshold. Note: the threshold to select genes to be kept is applied on the estimated raw counts after the filtering of step 2. The Z matrix is then subset according to the selected genes.
The x-axis in the figures below is on a log10 scale.

```{r}
figure4 = json_copy$figures$sd_histogram
figure5 = json_copy$figures$mean_histogram
```


```{r echo = FALSE, out.width = '50%', fig.cap= "Figure 4. Histogram of the standard deviation of the raw counts. Dotted blue line is the filtering threshold."}
knitr::include_graphics(figure4)
```

```{r echo = FALSE, out.width = '50%', fig.cap= "Figure 5. Histogram of the mean of the raw counts. Dotted blue line is the filtering threshold."}
knitr::include_graphics(figure5)
```

### Step 5

step_05.R performs principal component analysis (PCA) on the normalized and filtered matrix. It performs the following operations:

- Checks that the rows' means of the normalized and filtered matrix are equal or very close to 0.

- Checks that the rows' standard deviations of the normalized and filtered matrix are equal to 1.

- Performs PCA using prcomp().

- Saves the PC object as an RDS (R object), and the loading scores as a table.


```{r}
figure6 = json_copy$figures$scree_plot
figure7 = json_copy$figures$PC1_PC2
figure8 = json_copy$figures$PC2_PC3
```

```{r echo = FALSE, out.width = '50%', fig.cap= "Figure 6. Scree plot of the performed PCA."}
knitr::include_graphics(figure6)
```

Follow a visualization of PC1 vs. PC2 coordinates and PC2 vs. PC3. Note: there might be more than 3 principal components. Here I display the first three. To get the coordinates of all the found PCs, refer to the PC object found at:

```{r}
print(json_copy$path_2_results$pca_object)
```

```{r echo = FALSE, out.width = '60%', fig.cap= "Figure 7."}
knitr::include_graphics(figure7)
```

```{r echo = FALSE, out.width = '60%', fig.cap= "Figure 8."}
knitr::include_graphics(figure8)
```

### Step 6
step_06.R performs linear regression on the Eigenvalues vs component number, in order to select meaningful principal components. This selection technique presumes that the first PCs explain the variance in the data, while the last ones  represent noise, and should not be considered for the analysis. Because of this, the first components should have relatively high Eigenvalues compared to the last ones. In a scree plot, ideally we would see tall columns for the first PCs, and, when we get into noise, a sudden drop in eigenvalues that progressively level off. The program performs regression on the PC number from 1->N, 2->N, ... (N-2) -> N where N is the number of PCs. If N > 9, it stops the regression at N = 9 (or at N = json->input_variables->max_number_PC_regression).
Regression results (including slope, intercept, R-squared, and adjusted R-squared) are saved. A threshold given by json->input_variables->R_squared_threshold is used to determine which PCs are meaningful (i.e. they explain the variance in the data). This is because R-squared measures how close the data are to the fitted regression line. The higher is the R-squared valued, the more the eigenvalues for the considered PCs will be similar, and therefore those PCs can be considered noise. This will be clearer when looking at the plot below.
After determining the meaningful components, the script saves a new design file in which the coordinates on each meaningful PC are added as a new column.

```{r}
path_design_new = as.character(json_copy$path_2_results$design_meaningful)
design_new = read.table(file.path(path_design_new), header = TRUE, sep = "\t", row.names = 1)
kable(design_new)
```

It can be found at:

```{r}
print(json_copy$path_2_results$design_meaningful)
```


```{r}
figure9 = json_copy$figures$scree_plot_log10
figure10 = json_copy$figures$regression_plot
```


```{r out.width = '60%', fig.cap= "Figure 9. Log 10 of the Eigenvalues vs PC number. The last PCs usually do not explain the design equation variables. They represent noise.To determine whether PCs are representing noise and are therefore not interesting for the analysis, we regress on the log of the Eigenvalue vs the PC number. The regression slopes start to become closer as we get into the noise region. R squared values get closer to 1"}
knitr::include_graphics(figure9)
```

```{r out.width = '60%', fig.cap = "Figure10. The same plot as above, but with the regression line plotted in different colors. These are the lines whose R squared values are used to establish which PCs are meaningful."}
knitr::include_graphics(figure10)
```

Results of the regression PC number vs log10 eigenvalues:

```{r}
path_2_pc_eigen = json_copy$path_2_results$pc_vs_eigen
regression_pc_eigen = read.table(file.path(path_2_pc_eigen), header = TRUE, sep = "\t", row.names = 1)
kable(regression_pc_eigen, caption = "Regression of PC number vs log10 eigenvalues")
```

```{r}
R_squared_threshold = json_copy$input_variables$R_squared_threshold
print(paste("R squared maximum threshold:", R_squared_threshold))
print("Note: if this number is <=0 or >1, it is set back to default = 0.95")
```


### Step 7

step_07.R performs regression of the design equation variable vs each meaningful PC. The goal is to identify the meaningful PCs that explain certain design variables (e.g. "sex" or "treatment"). Step 7 is only an exploratory script. Currently, it cannot perform regression with interaction terms. Moreover, regression will not work if the regression variable has more than two categories. Refer to the design file with the added meaningful PCs, output of step_06, to perform more complex and accurate regression.

Variables for regression are taken from the input_json$design_variables. In this case they were:
```{r}
if (str_length(json$design_variables$design1) > 0 ){
  print(paste("variable1:", json$design_variables$design1))
}

if (str_length(json$design_variables$design2) > 0 ){
  print(paste("variable2:", json$design_variables$design2))
}
```


```{r out.width="50%", out.height="50%"}
all_figures = c()
for (i in 1:length(json_copy$figures$scree_plot_cor)){
  all_figures[i] = as.character(json_copy$figures$scree_plot_cor[i])
}
 
knitr::include_graphics(all_figures)
```


```{r}
all_tables = c()
for (i in 1:length(json_copy$path_2_results$correlation_table)){
  all_tables[i] = as.character(json_copy$path_2_results$correlation_table[i])
}

for (j in 1:length(all_tables)){
  result_table = read.table(file.path(all_tables[j]), header = TRUE, sep = "\t", row.names = 1)
  print(kable(result_table, caption = as.character(all_tables[j])))
}

```

