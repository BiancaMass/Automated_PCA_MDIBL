---
title: "Final Report"
output:
  html_document:
    toc: true
    toc_depth: 4
Author: "Original markdown Bianca Massacci"
params:
  json: ""
---

```{r include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r}
library(jsonlite)
library(ggplot2)
library(grid)
library(gridExtra)
library(genefilter)
library(knitr)
library(stringr)
```

```{r}
# Read the json file:
path2_json_file = file.path(params$json)
json = read_json(path2_json_file)
parent_folder = file.path(json$folders$parent_folder)
experiment = json$input_files$experiment_name
json_copy = read_json(file.path(parent_folder, "results", paste0(experiment, "_json_copy.json")))
```

Date and time:

```{r echo = FALSE}
print(Sys.time())
```

In this report you will find:

- Information about the input files (design matrix and estimated count matrix)

- A summary of what each step in the pipeline does

- Summary plots

- Output tables

## Input files
The input file can be found at the following location on your machine:
```{r}
path_2_design_file = json$input_files$infile1
path_2_counts_file = json$input_files$infile2
print(paste("Design file: ", path_2_design_file))
print(paste("Estimated counts file: ", path_2_counts_file))
```

```{r}
design = read.table(file.path(path_2_design_file), header = TRUE, sep = "\t", row.names = 1)
counts = read.table(file.path(path_2_counts_file), header = TRUE, sep = "\t", row.names = 1)
kable(design, caption = "Input design matrix.")
```

```{r}
kable(head(counts), caption = "The first 6 rows of the input estimated counts matrix")
```

```{r}
kable(summary(counts), caption ="Statistical summary of the estimated counts matrix.")
```

## Scripts

### step_01.R
Step 1 in the pipeline makes sure that the input files are valid and compatible with the pipeline requirements. It performs the following operations:

- Checks that design and counts files exist.

- Checks that design and counts files are not empty.

- Prints a warning message if the est. count matrix has NAs.

- Checks for a 1-1 correspondence between the rownames of the design file and the column names of the est. counts file.

### step_02.R
Step 2 in the pipeline normalizes the matrix using rlog() or vst() depending whether sample number is, respectively, <= 30 or >30.
It performs the following operations:

- Rounds the count matrix

- Removes rows with few counts according to the variable set in the json:input_variables->min_gene_tot_raw_count.

- Filters for rows with a mean above the mean threshold set in the json:input_variables->mean_precentage_threshold.

- Calculates mean and standard deviation for each gene across all samples.

- Constructs a DESeq data set using the counts matrix, the design matrix, and as a design formula the one indicated in json->design_formula->design.

- Uses rlog() or vst() to normalized the count matrix, preparing it for PCA.

The means and standard deviations of each gene across samples (before any normalization) can be found at:

```{r}
path_2_counts_mean = json_copy$path_2_results$genecounts_means
path_2_counts_sd   = json_copy$path_2_results$genecounts_sd
print(paste("gene counts means: ", path_2_counts_mean))
print(paste("gene counts standard deviations: ", path_2_counts_sd))
```

The rlog() or vst() normalized matrix can be found at:

```{r}
if (file.exists(as.character(json_copy$path_2_results$normalized_rld))){
  path2_matrix_norm_1 = json_copy$path_2_results$normalized_rld
  print(path2_matrix_norm_1)
  norm_1 = read.table(path2_matrix_norm_1, header = TRUE, sep = "\t", row.names = 1)
  kable(head(norm_1), caption = "The first six rows of the matrix after rld() normalization.")
  kable(summary(norm_1), caption = "Statistical summary of the rld() normalized matrix.")
} else if (file.exists(as.character(json_copy$path_2_results$normalized_vst))) {
  path2_matrix_norm_1 = json_copy$path_2_results$normalized_vst
  norm_1 = read.table(path2_matrix_norm_1, header = TRUE, sep = "\t", row.names = 1)
  kable(head(norm_1), caption = "The first six rows of the matrix after vsd() normalization.")
  kable(summary(norm_1), caption = "Statistical summary of the vsd() normalized matrix.")
} else {print("There must have been an error in the running of the pipeline.
              Please check that all your input files match the requirements.
              If they do, refer to step_02.R for debugging.
              Feel free to contact the author if you have any questions.")}



```


### step_03.R
Step 3 further normalized the matrix appliying a Z-transformation such that $Z = (x-mean) / standardDeviation$ . It does so by performing the following operations:

- Removes rows with few counts according to the variable set in the json:input_variables:min_gene_tot_raw_count.

- Filters for rows with a mean above the mean threshold set in the json:input_variables:mean_precentage_threshold.

- Calculates mean and standard deviation for each gene across all samples.

The Z table (after normalization) can be found at:
```{r}
path2_Z = json_copy$path_2_results$Z_table
print(path2_Z)
```

A Z table with two column added, one for mean and one for standard deviation of each gene across samples, can be found at:
```{r}
path2_Z_mn_sd = unlist(json_copy$path_2_results$Z_with_mean_sd)
print(path2_Z_mn_sd)
```
```{r}
figure1 = json_copy$figures$raw_mean_sd
figure2 = json_copy$figures$rld_mean_sd
figure3 = json_copy$figures$Z_mean_sd
```

```{r echo=FALSE, out.width = '50%', fig.cap="Fig 1. Mean vs standard deviation for the estimated count matrix after rows with a mean above the minimum threshold were filtered out(step 1 and 2)"}
knitr::include_graphics(figure1)
```

```{r echo=FALSE, out.width = '50%', fig.cap="Fig 2. Mean vs standard deviation after rlog() or vst() transformation"}
knitr::include_graphics(figure2)
```

```{r echo=FALSE, out.width = '50%', fig.cap="Fig 3. Mean vs standard deviation after Z transformation. If the pipeline worked properly, mean should be very close to 0 and standard deviations should be == 1."}
knitr::include_graphics(figure3)
```

### step_04.R

Step 4 reduces to genes with either sufficient variation or average expression level. To do so, it uses the threshold on A and/or SD set in the JSON input file. It performs the following operations:

- Extract the mean and sd threshold from the JSON file. 
  Note: if they do not exist, default is set at first quartile (0.25)
  
- Subsets the Z normalized matrix by only keeping values above the set threshold.

Below is a visualization of the threshold. Note: the threshold is based on the estimated raw counts (before normalization), but it is applied after raw counts have been filtered in the first passages of step 02 (before the construction of the DESeq data set). See step 02 above.
In step 04, after determining the value corresponding to the threshold set in the JSON (e.g. the first quartile by default), the script saves the gene names with mean and sd values above the threshold, and filters the Z matrix to only keep those genes.
The x-axis in the figures below has a log10 scale.

```{r}
figure4 = json_copy$figures$sd_histogram
figure5 = json_copy$figures$mean_histogram
```


```{r echo = FALSE, out.width = '50%', fig.cap= "Figure 4. Histogram of the standard deviation of the raw counts. Dotted blue line is the filtering threshold."}
knitr::include_graphics(figure4)
```

```{r echo = FALSE, out.width = '50%', fig.cap= "Figure 5. Histogram of the mean of the raw counts. Dotted blue line is the filtering threshold."}
knitr::include_graphics(figure5)
```

### step_05.R

Step 05 performs principal component analysis (PCA) on the normalized and filtered matrix. It performs the following operations:

- Checks that the rows' means of the normalized and filtered matrix are equal or very close to 0.

- Checks that the rows' standard deviations of the normalized and filtered matrix are equal to 1.

- Performs PCA using prcomp().

- Saves the PC object as an RDS (R object), and the loading scores as a table.


```{r}
figure6 = json_copy$figures$scree_plot
figure7 = json_copy$figures$PC1_PC2
figure8 = json_copy$figures$PC2_PC3
```

```{r echo = FALSE, out.width = '50%', fig.cap= "Figure 6."}
knitr::include_graphics(figure6)
```

```{r echo = FALSE, out.width = '60%', fig.cap= "Figure 7."}
knitr::include_graphics(figure7)
```

```{r echo = FALSE, out.width = '60%', fig.cap= "Figure 8."}
knitr::include_graphics(figure8)
```

### step_06.R
Step 6 performs linear regression on the Eigenvalues vs component number, in order to select for meaningful principal components. The idea is that the first components will explain the variance in the data, while the last ones will only be noise, and should not be considered for the analysis. In order to determine which components are noise and which are not, we regress on the PC number from 1->N, 2->N, ... N-2 -> N where N is the number of PCs. If N > 9, we stop the regression at N = 9 (or at N = json->input_variables->max_number_PC_regression.
We extract the results of each regression including slope, intercept, R-squared, and adjusted R-squared. R-squared measures how close the data are to the fitted regression line. e.g. for only 2 points, R squared will = 1 because the fit line will pass through both points.
For our purposes, the higher is the R-squared valued, the more the eigenvalues for the considered PCs will be similar, and therefore those PCs can be considered noise. This will be clear when looking at the plot below. The threshold for a maximum adjusted R-squared is set in the JSON file. Default = 0.95.
After determining the meaningful components, the script saves a new design file with each meaningful PC added as a new column.

```{r}
path_design_new = as.character(json_copy$path_2_results$design_meaningful)
design_new = read.table(file.path(path_design_new), header = TRUE, sep = "\t", row.names = 1)
kable(design_new)
```

It can be found at:

```{r}
print(json_copy$path_2_results$design_meaningful)
```


```{r}
figure9 = json_copy$figures$scree_plot_log10
figure10 = json_copy$figures$regression_plot
```


```{r out.width = '60%', fig.cap= "Figure 9. Log 10 of the Eigenvalues vs PC number. The last PCs usually do not explain the design equation variables. They represent noise.To determine whether PCs are representing noise and are therefore not interesting for the analysis, we regress on the log of the Eigenvalue vs the PC number. The regression slopes start to become closer as we get into the noise region. R squared values get closer to 1"}
knitr::include_graphics(figure9)
```

```{r out.width = '60%', fig.cap = "Figure10. The same plot as above, but with the regression line plotted in different colors. These are the lines whose R squared values are used to establish which PCs are meaningful."}
knitr::include_graphics(figure10)
```

Results of the regression PC number vs log10 eigenvalues:

```{r}
path_2_pc_eigen = json_copy$path_2_results$pc_vs_eigen
regression_pc_eigen = read.table(file.path(path_2_pc_eigen), header = TRUE, sep = "\t", row.names = 1)
kable(regression_pc_eigen, caption = "Regression of PC number vs log10 eigenvalues")
```

```{r}
R_squared_threshold = json_copy$input_variables$R_squared_threshold
print(paste("R squared maximum threshold:", R_squared_threshold))
```


### step_07.R

Step 7 performs regression of the design equation variable vs each meaningful PC. To perform further analysis (e.g. correlation with interaction terms, refer to the design file with the added meaningful PCs, output of step_06).
Variables for regression are taken from the input_json$design_variables. In this case they were:

```{r}
if (str_length(json$design_variables$design1) > 0 ){
  print(paste("variable1:", json$design_variables$design1))
}

if (str_length(json$design_variables$design2) > 0 ){
  print(paste("variable2:", json$design_variables$design2))
}
```


```{r out.width="50%", out.height="50%"}
all_figures = c()
for (i in 1:length(json_copy$figures$scree_plot_cor)){
  all_figures[i] = as.character(json_copy$figures$scree_plot_cor[i])
}
 
knitr::include_graphics(all_figures)
```


```{r}
all_tables = c()
for (i in 1:length(json_copy$path_2_results$correlation_table)){
  all_tables[i] = as.character(json_copy$path_2_results$correlation_table[i])
}

for (j in 1:length(all_tables)){
  result_table = read.table(file.path(all_tables[j]), header = TRUE, sep = "\t", row.names = 1)
  print(kable(result_table, caption = as.character(all_tables[j])))
}

```

